---
title: "Analysis of STAR data through an ANOVA model"
author: "Chengkai Shi"
date: "2023-3-18"
output:
  html_document:
    df_print: paged
    number_sections: yes
---

```{r global_options, include=FALSE}

# This part consists of the R codes used for data analysis.

knitr::opts_chunk$set(fig.pos = 'H')

```

```{r getlabels, echo=FALSE}
labs=knitr::all_labels()
labs=labs[!labs %in% c("setup","getlabels","allcode")]

```

```{css, echo=FALSE}  
h1 {font-size: 30px;}
h2 {font-size: 22.5px;}
h3 {font-size: 17px;}
```

***

# Abstract

Based on the famous Project STAR, we conduct our own statistical analysis on how math scores in first grade are associated with the 2 factors: class types and schools. We aggregate the original dataset, and establish a two-way ANOVA model by applying WLS estimation and Box-cox transformation. After modifications and tests, our model succeeds in revealing the relationship between math scores and the chosen factors, without violating any assumptions. This ANOVA model also performs well in the sensitivity analysis. Finally, we validates the benefits of small class type to student's math scores, and find out schools that provide the best education in first-grade math.

***


# Introduction

## Existing research

Among those studies on class types, the Tennessee Student/Teacher Achievement Ratio study (Project STAR) is a well-known one that explores the association between class types and students' test scores in their early school grades. This longitudinal project lasted for over four years and investigated a large number of students, schools and teachers. Three class types: "small", "regular", and "regular with aide" were the core factor in Project STAR. Other factors like schools' location, lunch status and teachers' races, which might be influential, were also involved. 

Experiments in Project STAR are well-designed on the basis of a randomized controlled trial approach. For one thing, students were randomly put into a certain class type, while one teacher was randomly assigned to one single class. For another, test scores were scaled to ensure fairness across different classes and schools. Such arrangements follow an "effects of causes" logic and facilitate further causal inference studies. Thanks to the comprehensive investigations in this project, we are able to get access to the "STAR" dataset and conduct our own analysis on it. 


## Questions of interest

The original study collected scaled scores of various subjects across several grades. To narrow down our own topic, the only test score we look at is the math scaled scores of first grade. Meanwhile, from all factors involved, we pick up 2 major factors: class type and school ID. We do not care about students' changes across different grades, but only the records in first grade. Same as the original design, we also look into 3 class types: small, regular, regular with aide. For simplicity, "math scaled score" is abbreviated as "math score".

As a simplified version of Project STAR, our own study is carried out with three questions of interest:

(1) Across all class types, are there any differences in students' math scores of first grade?

(2) If such differences do exist, which class type is associated with the highest math score of first grade?

(3) Apart from class types, how schools are associated with math scores of first grade? And which is the best school with the highest math score?

Our small-scale study focuses on the academic performance of first grade students, exploring the relationship between math scores and the 2 chosen factors. In terms of real-life significance, our work may give guidance to educational adjustments of the class size, and promote improvements in teaching in certain schools. It can also enlighten further research on other academic indicators, such as test scores of other subjects, or students' future achievements.

***

# Background 

## Dataset acquisition

For our analysis, the origin "STAR" dataset is from Harvard dataverse, a free data repository supported by Harvard University. This dataset contains 11601 observations and 379 variables. Each observation corresponds to an individual student, while the variables cover all kinds of information from schools, teachers and students. 

Among all given variables, some record students' test scores in different grades, such as "g1tmathss", "g2treadss". Some givens identity information of students, teachers and schools, such "stdntid", "g1tchid" and "g1schid". Moreover, variables like "yearsstar" and "FLAGSG1" reflect individuals' participation in Project STAR, while "g1tcareer" and "g1surban" provide extra background information of teachers and schools. Most importantly, there are a series of variables, such as "g1classtype", which represents the class type that a student was in at a certain grade. 


## Caveats in the initial analysis

Our initial analysis of "STAR" dataset before has several caveats. Here are some typical ones.

(1) The original dataset was not well aggregated.

(2) No transformation of the outcome is considered, thus causing the residuals to be non-normal.

(3) Only ordinary least squares is considered, which leads to severe heteroscedasticity in residuals.

(4) The effect of schools is not discussed in detail.

These caveats will be fixed one by one in this final report. For each of them, a detailed solution will be proposed, in order to make our new model more plausible.

***

# Descriptive analysis 

## Data preprocessing

Before visualization, we must preprocess the dataset. Confronted with various problems in the original dataset, we take different measures to deal with them. We finally extract a new dataset with 325 data points and 3 variables.

### Missing values

It is obvious that there are a huge number of missing values ("NA") in the original dataset. We observe that in one observation, missing values never appear alone. For example, if an observation has a missing value in "g1schid", one important factor that we care, it tends to have missing value in other key variables, such as "g1tchid" and "g1tmathss". Therefore, we delete all observations with missing values in the dataset because they contain no useful information for our analysis.

### Aggregation

To answer our questions of interest, we pick up 4 relevant variables for modeling. "g1tmathss" represents the math scores of first grade, which is treated as the outcome. "g1classtype" and "g1schid" are class types and school IDs, the 2 major factors. In addition, "g1tchid" is the teacher IDs for identifying students taught by the same teacher. 

After designating the variables, we aggregate all observations based on different teacher IDs ("g1tchid"). To be specific, for students from the same teacher, we choose the median of their math scores to aggregate their performance, considering that the range of scores can be so large that mean values or other quantiles can hardly summarize the overall pattern. In this way, we extract 339 valid data points, with each one corresponding to a single teacher or a single class. 

### Missing class types

Notably, some schools fail to collect all 3 class types, which violates the project's original experimental design. We find that there are 4 such schools, whose school IDs are: 244728, 244736, 244796, 244839. Here we delete all observations in such schools, because we are unable to make comparisons among class types in such schools. We choose not to supplement those missing class type with the mean value or other statistics, since such work brings no useful information. In this way, only 325 data points and 72 school ID levels are retained.

### Problems in students

Another problem lies in students themselves. Not all students stayed in the same class type for 4 full years. Even when we only care about math scores in first grade, we cannot ignore that some of them transferred into another class type from kindergarten to first grade. Here we apply an "intend-to-treat" idea to deal with this problem. That is to say, a student only belongs to the class type he/she was in at his/her first grade, no matter which type he/she was in before that. In this way, we only take the variable "g1classtype" as the class-type factor in our analysis. 

What is more, a large proportion of students did not participate throughout the entire project. In our study, the possible influence of kindergarten experiences on first grade is not discussed. Therefore, every student with a record in the variable "g1tmathss" is treated equally, no matter if he/she has academic records in kindergarten.

```{r,echo=F,results=F,message=F, warning=FALSE}
# packages
library(haven)
library(dplyr)
library(gplots)
library(car)
library(MASS)

```

```{r,echo=F,results=F,message=F, warning=FALSE}
# preprocess the dataset, delete the missing values and aggregate the observations
STAR=read_sav("STAR_Students.sav")
STAR1=subset(STAR, select=c('g1tmathss','g1classtype','g1schid','g1tchid','yearsstar','FLAGSGK','FLAGSG1'))
STAR2=na.omit(STAR1) 
STAR2$g1classtype=as.factor(STAR2$g1classtype)
STAR2$g1schid=as.factor(STAR2$g1schid)
s=n_distinct(STAR$g1schid)
STAR3=aggregate(g1tmathss~g1schid+g1classtype+g1tchid, STAR2, median)          # aggregate the dataset by teacher
STAR_pair=STAR3[,-3]
STAR_delete=STAR3[!(STAR3$g1schid %in% c(244728, 244736, 244796, 244839)), ]
STAR4=subset(STAR_delete, select=c('g1tmathss','g1classtype','g1schid'))       # the final dataset we use

# Check the schools with fewer than 3 class types
STAR_school=aggregate(g1tmathss~g1schid+g1classtype, STAR2, median)      
table_school=table(STAR_school$g1schid)
fail=length(which(table_school<3))
```


## Data visualization

### Variable v.s. variable

Now we conduct an in-depth investigation on the processed dataset and the variables in it. Figure 1 shows the pairwise matrix of the outcome and 2 factors. We can clearly see the different levels of factors. This indicates that the two factors should be treated as dummy variables when it comes to model fitting. 

The 3 levels of class type are: small($i=1$), regular($i=2$), regular with aide($i=3$). In the context of randomized controlled trials, the factor class type has 3 groups, while school ID has 72 groups. As a result, there are totally $3*72=216$ cells.   

### Boxplots

We apply boxplots to investigate the 2 factors under different levels to see how the observations are distributed. According to the Figure 2, for class type, the medians of its 3 levels are relatively close to each other, but "small" class type has the highest one among them. Moreover, "small" class type has the largest score range, while "regular with aide" has the smallest. 

In addition, there is one outlier (619.5) in "small" class type, and one (588.0) in "regular" class type. However, since these outliers do not deviate much from the general pattern, we can regard them as non-influential, and decide not to delete them from the dataset.

On the other hand, as is shown in Figure 3, the school with ID=165199 has the highest median over 570. Because of the large number of levels, the upper and lower quantiles of different schools fluctuate greater than those of class types. This indicates that there might exist significant differences in math scores across schools. In addition, a couple of outliers do exist in some schools.

### Main effect plots

The main effect plots illustrate the effects of different levels of the 2 factors. According to Figure 4, "small" class type has an effect much larger than that of other levels. On the other hand, Figure 5 shows that the main effects of different schools fluctuate greatly. We can also a preliminary perception that effects of the 2 factors are significant, and there do exist differences across different factor levels. Besides, the sample sizes of different levels in each factor are close to each other. 

```{r,echo=F,results=F,message=F, warning=FALSE, echo=FALSE}
# Box-plot
pairs(STAR_pair, pch=16, col="blue", cex=1, main="Figure 1: Pairwise plot")
par(mfrow=c(1,2))
boxplot(g1tmathss~g1classtype,data=STAR3, xlab="Classtype",ylab="Math score",main="Figure 2: Boxplot of classtype")
boxplot(g1tmathss~g1schid,data=STAR3, xlab="SchoolID",ylab="Math score",main="Figure 3: Boxplot of schoolID")
STAR_regular=STAR3[STAR3$g1classtype==2,]

# Main effect plot
par(mfrow=c(1,2))
plotmeans(g1tmathss~g1classtype,data=STAR3, xlab="Classtype",ylab="Math score",main="Figure 4: Main effect of classtype") 
plotmeans(g1tmathss~g1schid,data=STAR3, xlab="SchoolID",ylab="Math score",main="Figure 5: Main effect of schoolID")
#interaction.plot(STAR3$g1classtype, STAR3$g1schid, STAR3$g1tmathss,ylab="Math scores",xlab='Classtype')

```

***

# Inferential analysis 

## Notations

Here is a brief explanation of notations used in our model. Those less frequent notations will be explained once they are introduced.

| Notation | Explanation |
|--|-------|
|$i$| the index of class type groups |
|$j$| the index of school ID groups  |
|$k$| the index of observations in a cell |
|$\mu$ | the population mean across all cells |
| $n_{ij}$  | the number of observations in the $i,j$ cell        |
| $Y_{ijk}$ | the original k-th observation of math scores in the $i,j$ cell |
| $Y_{ijk}^{'}$ | the transformed k-th observation of math scores in the $i,j$ cell |
| $\alpha_i$| the main effect of the i-th level of class types    |
| $\beta_j$ | the main effect of the j-th level of school IDs     |
| $\epsilon_{ijk}$ | the original error term with regard to $Y_{ijk}$      |  
| $\epsilon_{ijk}^{'}$ | the weighted error term with regard to $Y_{ijk}^{'}$      |
| $w_{ij}$  | the weight of the $i,j$ cell in weighted least squares estimation |
| $\sigma_{ij}^2$| the within-cell variance of the $i,j$ cell |


## Model construction

### Model expression

A two-way ANOVA model is introduced to explore the association between the math score and 2 factors. Here is the expression of this model:
\begin{equation}
Y_{ijk}^{'}=\mu+\alpha_i+\beta_j+\epsilon_{ijk}^{'}, \ where \ i =1,2,3, \ j=1,\ldots,72, \ k=1,\ldots,n_{ij}.
\end{equation}

In this expression, the response $Y_{ijk}^{'}=$ is the math scores after Box-Cox transformation. Since $Y_{ijk}^{'}$ is a strictly increasing function of original $Y_{ijk}$, they are equivalent in terms of our questions of interest. Moreover, the error term $\epsilon_{ijk}^{'}=\sqrt{w_{ij}}\epsilon_{ijk}$ is a weighted error, where the weight $w_{ij}=\frac{1}{\sigma_{ij}^2}+0.01$ comes from the weighted least squares method. These special treatments will be discussed in chapter 5.3 later.  

Besides, we observe that there is not much difference among the sample sizes in different groups, so we just apply a balanced design in this model. That is to say, every $i,j$ cell is treated equally. Similar to a normal two-way ANOVA model, the main effect terms have constraints: $\sum_{i=1}^{3} \alpha_i=\sum_{j=1}^{72} \beta_j=0$.

Unfortunately, because of the special treatments, the fitted coefficients of this model can hardly be interpreted. As a result, we do not analyze the coefficients in this report.


### Assumptions

Here are basic assumptions of our two-way ANOVA model. These assumptions will be validated in chapter 6.1. 

(1) Transformed observations $Y_{ijk}^{'}$ are independent of each other.

(2) Weighted errors are independent and normally distributed, with zero mean and equal variance. These assumptions can be summarized as $\epsilon_{ijk}^{'}\stackrel{\text{i.i.d}} \sim N(0,\sigma^2)$.


## Model justification

The model in chapter 5.2.1 is the final model we can derive, and it went through multiple modifications before it is displayed. In this chapter, we introduce some key steps in the process of modeling, and show why we finally choose a model like that. 

If no changes are made, the original model can be expressed as: 
\begin{equation}
Y_{ijk}=\mu+\alpha_i+\beta_j+\epsilon_{ijk}, \ where \ i =1,2,3, \ j=1,\ldots,72, \ k=1,\ldots,n_{ij}.
\end{equation}

Unfortunately, this model cannot satisfy its assumptions: $\epsilon_{ijk}\stackrel{\text{i.i.d}} \sim N(0,\sigma^2)$. As a result, it is necessary to make some modifications to it and derive a new model. 

### Weighted least squares

If we simply fit a model by ordinary least squares (OLS), the model residuals can be erratic. According to a Levene test, residuals do not have a homogeneous variance.  

To balance residual variances, weighted least squares (WLS) is introduced into the model. The weight is usually the reciprocal of variances. Moreover, in case of some extremely small variances which may make their weights extremely large, a small constant is added to the weight to stabilize it. In this way, for residuals $\epsilon_{ijk}$, its weight can be expressed as $w_{ij}=\frac{1}{\sigma_{ij}^2}+0.01$. Residuals of WLS model  Through WLS, the problem of heteroscedasticity can be settled.


### Box-Cox transformation

If we just retain the original outcome $Y_{ijk}$, we can find that model residuals can hardly be normal according to a Levene test. Therefore, Box-Cox transformation is applied here to fix this problem. For a given parameter $\lambda$, the outcome is be changed into $Y_{ijk}^{'}=\frac{Y_{ijk}^{\lambda}-1}{\lambda}$ if $\lambda\neq 0$, and $Y_{ijk}^{'}=log(Y_{ijk})$ if $\lambda=0$.

According to the Box-Cox curve in Figure 6, under significance level $\alpha=0.05$, the optimal $\lambda$ is -2, which maximizes the log-likelihood of data points. For $\lambda<-2$, the log-likelihood barely increases. In this way, we consider the transformed outcome $Y_{ijk}^{'}=\frac{Y_{ijk}^{-2}-1}{-2}$ for our final model.

```{r, echo=F,results=F,message=F, warning=FALSE, echo=FALSE}
## Adjust our initial model

# WLS
table1=table(STAR_delete$g1schid)
group_var=tapply(STAR_delete$g1tmathss, STAR_delete$g1schid, var)
weights=1/group_var+0.01
w3=unlist(mapply(rep, weights, table1))

# Box-Cox
bc_out=boxcox(lm(g1tmathss~g1classtype+g1schid, data=STAR4, weight=w3))
bc_out$g1classtype[which.max(bc_out$g1tmathss)]; title(main="Figure 6:Box-Cox curve")
lambda=-2
STAR4$g1tmathss_new=(STAR4$g1tmathss^lambda-1)/lambda
```

### Tests of main effects

We conduct F-tests to examine if the 2 factors really take effect in the model. For class types, the null and hypotheses are: $H_0: \alpha_i=0$, $H_a$: not all $\alpha_i$ are zero. The full model is $Y_{ijk}^{'}=\mu+\alpha_i+\beta_j+\epsilon_{ijk}$ , versus reduced model $Y_{ijk}^{'}=\mu+\beta_j+\epsilon_{ijk}$. Under significance level $\alpha=0.05$, the F-statistic is $F^*=\frac{MSA}{MSE}$, with null distribution $F_0=F(0.95;2,251)$. Then we can check the ANOVA tables and calculate that $F^*=10.0593>F_0=3.0318)$. Therefore, we should reject $H_0$ and claim that the effects of class types is not all zero.

Similarly, for school IDs, the null and hypotheses are: $H_0: \alpha_i=0$, $H_a$: not all $\alpha_i$ are zero. Under F-statistic $F^*=\frac{MSB}{MSE}$ and $\alpha=0.05$, we can find that $F^*=14.3299>F_0=1.3477, which indicates that the effects of school IDs on math scores also exist. In this way, we cannot rule out either of the factors from the model.

### Test of the interaction term 

Apparently, our model includes no interaction term. Here we conduct a F-test to check if an interaction term is needed. Notably, we should keep using transformed outcomes and WLS here. In this F-test, the full model is  $Y_{ijk}^{'}=\mu+\alpha_i+\beta_j+\alpha\beta_{ij}+\epsilon_{ijk}$, versus the reduced model: $Y_{ijk}^{'}=\mu+\alpha_i+\beta_j+\epsilon_{ijk}$. 

The null and alternative hypotheses are: $H_0: (\alpha\beta)_{ij}=0$, $H_a$: not all $(\alpha\beta)_{ij}$ are 0. Under $\alpha=0.05$, the statistic is $F^{*}=\frac{MSAB}{MSE}$, with null distribution $F_0=F(0.95;142,251)$. It can be computed that $F^{*}=1.3091$, $F_0=1.3508$. Since the F-statistic is smaller than $F_0$, we are unable to reject $H_0$, and then exclude the interaction term from the model.

```{r, echo=FALSE}
# Fit an initial ANOVA model without any special treatments
fit1=aov(g1tmathss~g1classtype+g1schid, data=STAR4)
sum1=summary(fit1)
res1=fit1$residuals
```

```{r,echo=FALSE, warning=FALSE}
# Test the 2 factors
full_model=lm(g1tmathss_new~g1classtype+g1schid,data=STAR4, weight=w3)
reduced_model0=lm(g1tmathss_new~g1schid, data=STAR4, weight=w3)
reduced_model1=lm(g1tmathss_new~g1classtype, data=STAR4, weight=w3)
an1=anova(full_model)
an1_0=anova(reduced_model0); an1_1=anova(reduced_model1)
alpha=0.05
MSA=(4.9484-4.5812)/2 
MSB=(23.151-4.5812)/71
MSE=4.5812/251
Fstar_1=MSA/MSE ; F0_1=qf(1-alpha,df1=2,df2=251)
Fstar_2=MSB/MSE ; F0_2=qf(1-alpha,df1=71,df2=251)

# Test the interaction term
full_model2=lm(g1tmathss_new~g1classtype+g1schid+g1classtype*g1schid,data=STAR4, weight=w3)
reduced_model2=lm(g1tmathss_new~g1classtype+g1schid,data=STAR4, weight=w3)
an2=anova(full_model2)
an3=anova(reduced_model2)

SSE_f=1.6933; SSE_r=4.5812; df_f=109; df_r=251
Fstar_int=((SSE_r-SSE_f)/(df_r-df_f))/(SSE_f/df_f)
F0_int=qf(1-alpha,df1=df_r-df_f,df2=df_f)

```

```{r,echo=FALSE, warning=FALSE}
# final model
fit3=lm(g1tmathss_new~g1classtype+g1schid, data=STAR4, weight=w3)
sum3=summary(fit3)
res3=fit3$residuals
an4=anova(fit3)

```

## Discussion on questions of interest

### Discuss on class types

First of all, we examine if there are really differences in effects across different levels. For class types, we exploit a F-test to check the differences among small, regular and regular with aide. The hypotheses are $H_0:\alpha_1=\alpha_2=\alpha_3$ versus $H_a:$ not all $\alpha_i$ are equal. Under $\alpha=0.05$, the F-statistic is $F^*=\frac{MSTR_{\alpha}}{MSE}$, with null distribution $F_0=F(0.95;2,251)$. Through the ANOVA table of our final model, we can calculate that $F^*=11.8011>F_0=3.0318$. Therefore, we can reject $H_0$ and conclude that there are differences in math scores across all 3 class types.

To determine which class type is associated with the highest math score, a Tucky range test is introduced here. Through pairwise subtraction across 3 levels, we can compute the 95% confidence intervals of each pair, as is shown in the table below. We notice that the effect of "small" class size is much larger that of the other 2 types, with confidence intervals not including 0. "Small" class type is definitely associated with the highest math scores.

In contrast, the confidence interval of the pair "3-2" crosses 0, but is slightly skewed towards the positive x-axis. This means that "regular" class type is a little worse than "regular with aide", but in fact, we cannot distinguish between them. 

```{r,echo=FALSE, warning=FALSE}
# F-test to examine the differences
an4=anova(fit3)
MSTR_alpha=2.1537 ; MSTR_beta=2.6155; MSE=0.1825
F1_3=MSTR_alpha/MSE; F0_3=qf(1-alpha,2,251)
F1_4=MSTR_beta/MSE; F0_4=qf(1-alpha,71,251)


# Tucky range tests to determine the highest scores 
alpha=0.05
idx1=STAR3$g1classtype; idx2=STAR3$g1schid
mu_i=tapply(STAR3$g1tmathss, INDEX=idx1, mean); max_i=which.max(mu_i)
mu_j=tapply(STAR3$g1tmathss, INDEX=idx2, mean); max_j=which.max(mu_j)
Tu=TukeyHSD(fit1, conf.level=1-alpha)
Tu1=Tu$g1classtype; Tu2=Tu$g1schid;
print(Tu1)

```

### Discussion on school IDs

Similarly, another F-test is used here to examine the differences in math scores across school IDs. With $H_0: \beta_1=\beta_2=\cdots=\beta_{72}$ versus $H_a:$ not all $\beta_j$ are equal and F-statistic $F^*=\frac{MSTR_{\beta}}{MSE}$. We can also get $F^*=14.3315>F_0=1.3477$, and thus reject $H_0$. In this way, we can claim that there are some differences in math scores across most schools, with a small part of them very close to each other. 

We also exploit a Tucky range test to examine differences in schools. We find that the school with ID=165199 corresponds to the highest math scores. It can be considered as the best school in math education.

***

# Sensitivity analysis 

## Model diagnosis

We focus on residuals to diagnose the two-way ANOVA model in chapter 5.2.1. We can take for granted that all observations of students' math scores are independent thanks to the trustworthy data collection of this famous experiment. Therefore, the residuals can be considered independent as well. We mainly check the normality and equal variance of residuals by drawing several charts and conducting different tests. 

### Normality Test

To test normality, we first look at the histogram and Q-Q plot in Figure 8. For one thing, the histogram of residuals is very close to that of a normal distribution with zero mean. For another, the Q-Q plot is neither left-skewed nor right-skewed, with most data points on the standard line. This supports our statement about the histogram.

Given that there are only 325 data points, it should be considered as a small sample size. Hence, a Shapiro-Wilk test is suitable to further examine the normality. Under $\alpha=0.05$, the test's p-value is much larger than 0.05. This means we should accept $H_0$, and claim that the residuals of our model are normally distributed with zero mean.

### Equal variance test

From Figure 7, residuals are distributed evenly as the fitted value increases, without an apparent trend. Therefore, it can be preliminarily inferred that residuals have an equal variance.

To further examine if residual really have the equal variance, a Levene test is used. The null and alternative hypotheses are: $H_0:$ all $ \sigma_{ij}^2$ are equal to $\sigma^2$, versus $H_a:$ not all $ \sigma_{ij}$ are equal. Under $\alpha=0.05$, the p-value of this test is larger than 0.05. Therefore, we fail to reject the null hypothesis and acknowledge that the variances are all an equal constant.


## Robustness of the model

In this part, we make some changes to some procedures in our data analysis, and check if the results stay the same. Apart from directly justifying the established ANOVA model, this is another good way to verify our results and conclusions. This also reflects how robust our model is. 

When aggregating the observations before the model is set up, we can choose the mean values instead of the median in chapter 4.1.2. Moreover, we can delete all outliers we spot in Figure 2, instead of keeping them. Also, we can supplement the missing class types in some schools with the mean or median of other schools. Under these circumstances, our main results still stay the same. Small class type is still associated with highest math scores. The only change is the choice of the best school in math education. 

```{r, echo=FALSE}
### Model diagnosis

# Residual plot
plot(fit3$fitted.values, fit3$residuals, xlab="Fitted Values", ylab="Residuals", main="Figure 7: Residuals vs Fitted Values")
abline(h=0, col="red")

# Normality test
par(mfrow=c(1,2))
hist(res3, main="Figure 8: Histigrams of residuals") 
qqnorm(res3); qqline(res3,main="Figure 9: Q-Q plot")

sw=shapiro.test(res3)  # S-W test
p_sw=sw$p.value

# Check the Box-Cox curve
MASS::boxcox(fit3);title(main="Figure 9: Box-Cox Curve after fitting")

# Equal variance test
STAR4$interaction=interaction(STAR4$g1classtype,STAR4$g1schid)
le=leveneTest(g1tmathss_new~g1classtype*g1schid, data=STAR4)

```

***


# Discussion 

## Findings

With respect to our questions of interest, we have the following findings:

(1) Between "small" class type and the other two, there are significant differences in math scores of first grade. "Regular" and "regular with aide", however, are not so different from each other.

(2) "Small" class type is related to the highest math scores in first grade.

(3) The school with ID=165199 is related to the highest math scores. It performs best in math education.

Compared with results in our initial analysis, we do not have so many new findings, except the choice of the best school. However, now our results are obtained from a better model and more rigorous causal inference, which makes them more convincing.

## Caveats of the model

Our model succeeds in unfolding the positive effects of small class size on students' math scaled scores. However, there are still some caveats in the whole process of data analysis. First of all, due to special treatments like WLS and Box-Cox transformations, the fitted coefficients of our model is hard to interpret. Because of this, it is almost impossible to make more profound studies on the mechanisms of factors.

Moreover, we simply choose the most commonly used weight for WLS. An inappropriate weight may disturb the function of Box-Cox transformation. Fortunately, our model passes the test on normality and equal variance. However, better approaches to determining the weight and the parameter $\lambda$ are still needed.


## Conclusion

For first grade students, small class type is most beneficial to their math grades. Among all the schools, the one with school ID=165199 provides the best math education. Our study only focuses on students of first grade, but our findings generally coincide with the overall results of original Project STAR. It is easy to see the strong impact of class types on students' test scores, along with the great advantage of small class type, no matter in one subject or students' overall achievements.

***

# Acknowledgement {-}

Data analysis and report writing are completed independently.

Here is the Github link of this report (a html file). This link is also attached as a comment in the submission.

https://github.com/Frankieyyy/STA-207-FinalProject/blob/main/final_report.html


# Reference {-}

[1] Finn, J. D., Fulton, D., Zaharias, J., & Nye, B. A. (1989). Carry-over effects of small classes. Peabody Journal of Education, 67(1), 75-84. doi: 10.1080/01619569209538670

[2] Mosteller, F. (1995). The Tennessee study of class size in the early school grades. The future of children, 113-127. doi: 10.2307/1602360

[3] https://github.com/ChenShizhe/StatDataScience/blob/master/Notes/Chapter4ANOVA.ipynb

[4] https://github.com/ChenShizhe/StatDataScience/blob/master/Notes/Chapter4ANOVAII.ipynb


# Appendix {-}
```{r allcode, ref.label=labs,eval=FALSE}
```

# Session info {-}

```{r}
sessionInfo()
```